%--------------------------------------
\chapter{Introduction}
\label{chap_intro}
%--------------------------------------


Cryptography is essential in making sure data is confidential and secure in the modern world. Making sure cryptography primitives are used correctly, however, has always been difficult problem to solve whether it be in critical systems like banking or the widespread misuse of cryptographic API found in mobile and web apps. These misuses can lead to vulnerabilities that allow for data leaks. To solve this problem researchers have designed tools that can be integrated into the development pipeline that catch these misuses and allow developers to find the problems before they release software to the public. These tools are known as crypto-API misuse detectors also known as crypto-detectors. These crypto-detectors are vital to helping keep development of applications secure. However, these crypto-detectors are not without their own faults.

crypto-detectors see widespread use across IDEs, corporate testing suites, by source control platforms (such as GitHub), and comercial use. crypto-detectors are relied upon by many developers that deal with sensitive information, there is an expectation and an assumption that they are reliable. Developers utilize these crypto-detectors to help have peace of mind that their code is now more secure. However, a lot is still unknown about how effective they are at crypto-API misuse despite how eager developers are to adopt them. The MASC framework \cite{Ami_2022}, presented in the orignal paper tried to provide a solution to this problem by providing a framework to evaluate crypto-detectors beyond simple manually created benchmarks.

As described in the original paper MASC is "the first systematic, data-driven framework that leverages the well-founded approach of Mutation Analysis for evaluating Static Crypto-API misuse detectors." MASC is used by a user in a similar manner to typical mutation analysis. MASC is capable of "mutating Android/Java apps by seeding them with mutants" containing crypto-API misuse. The mutated apps can then be analyzed by a crypto-detector and seeing which mutants are not located during the analysis reveals both design and implementation flaws in that crypto-detector.

For my thesis I took the already existing MASC framework and extended it. This was done by adding a variety of new functionality and greatly expanding the functionality that already existed. I expanded MASC in both depth and width. The updated MASC framework was also used to reevaluate crypto-detectors that were evaluated by the original paper and evaluate five additional crypto-detectors. With the new additions to MASC and new evaluation I was able to determine: do misuses that were reported and fixed have a tendency to reappear in future builds, have crypto-detectors improved since the original paper, can MASC discover new flaws in crypto-detectors, what are the characteristics of these flaws, and what is the impact of the flaws on the effectiveness of crypto-detectors in practice?



%--------------------------------------
\section{Overview}
\label{ch1:sec:overview}
%--------------------------------------


The original MASC framework was built based on a Crypto-API Misuse Taxonomy. At the time is was the first comprehensive taxonomy of crypto-API misuse cases containing 105 cases. These were found using a data driven process that systematically identified, studied, and extracted misuse cases from both academic and industrial sources published from 1998-2018. This taxonomy provided the main building block for designing mutants that can emulate realistic misuses. For my thesis we expanded this taxonomy to cover papers from 2019-2022. The extended taxonomy includes 19 more papers and 13 more misuses.

MASC also had several Crypto-Mutation Operators and Scopes. These different abstractions were designed to allow flexibility in MASC to create a large variety of feasible mutants. The threat model MASC is based on consists of three types of threats that crypto-detectors are likely to face: benign developer accidental misuse (T1), benign developer harmful fix (T2), and evasive developer harmful fix (T3). In addition, MASC also consisted of usage base mutation operators which were general operators that contain common characteristics that can leverage a diverse set of crypto APIs to create misuse cases that can be found within the taxonomy. These operators consist of two main categories: restrictive, where a developer can only instantiate certain objects by providing values from a predefined set such \inline{Cipher.getInstance(<parameter>)} and flexible which consists of operators with a large amount of extensibility such as developers can customize the hostname verification component of the SSL/TLS handshake by creating a class extending the HostnameVerifier, and overriding its verify method, with any content. The original set of operators consisted of 12 operators (six restrictive and six flexible). For my thesis I focused on expanding the amount of restrictive operators since more are necessary to fully represent the taxonomy.  This is due to the fact that restrictive operators take in a specific set of inputs from the user and represent one or more misuse cases while the flexible operators are designed to represent many. Due to this focus was placed on the expansion of restrictive operators since more are necessary to capture the whole taxonomy. I added seven  additional restrictive operators to the total count based both on misuses that were not represented from the original taxonomy and to represent the extended taxonomy. I also added restrictive operators to further extend representation of the evasive developer (T3) since the original work was intentionally conservative with imagining what evasive developers were capable of. After more research it was determined that new operators could be created to emulate more evasive behavior while still being statically computable. MASC also includes three types of mutation scopes that allow for seeding of mutants variable fidelity to realistic API-use and threats.

I also expanded MASC to contain several new features. These consist of adding an automated analysis tool and the sensitivity evaluator. The automated analysis provides MASC with a way to automatically evaluate a crypto-detector's output and determine which misuses were caught or not. It leverages Static Analysis Results Interchange Format (SARIF) files (a file type similar to JSON) to determine where misuses were. It is also designed to catch flaws with crypto-detectors based on output. The new component can test a variety of cases against a crypto-detectors that range in complexity and will report if a simple case fails to be caught and stop running, since a more complex case cannot be feasibly caught if the simple version fails. Since all evaluation from the original paper was done by hand and was very time-consuming to ensure accuracy. This tool was designed to help researchers and users save time while evaluating crypto-detectors and ensure accuracy. This tool was further expanded by other developers to be capable of doing full end to end analysis with crypto-detector by running the crypto-detector as a part of MASC.

The other main new feature introduced as a part of MASC is the sensitivity evaluator. This tool defined the different types of sensitivities commonly associated with crypto-detectors: flow, object, context, path, and alias sensitivity. Certain tools claim to be built with these sensitivities in mind. These were used to categorize all the operators contained under one or more of these categories. MASC can then be run and will generate mutants only for the specified sensitivity type. This allows for a lower barrier to entry for users and to allow users to test mutants specifically against the claims of a crypto-detector. 

For the evaluation of crypto-detectors I used the same methodology as the original paper but extended the number of operators and the number of applications. I evaluated eight of the major crypto-detectors used in the original paper and also evaluated five addition crypto-detectors. The original paper also evaluated the crypto-detectors with a 15 different Android/Java applications and a group of minimal cases. All of these same applications and minimal cases were used again in evaluation with the addition of 16 new Android/Java applications that were mutated using the newly extended MASC as well as a group of new minimal cases to test the new operators. Additionally, my findings were disclosed to the designers/maintainers of the tools. 


%--------------------------------------
\subsection{Motivation and Background}
\label{ch1:subsec:motivation}
%--------------------------------------

The motivation for extending MASC remains consistent with the original motivation behind MASC, "Insecure use of cryptographic APIs is the second most common cause of software vulnerabilities after data leaks." Many developers are likely to use crypto-detectors in their development pipeline since they are not experts in the area but wish to catch vulnerabilities before releasing software. This means that the reliability of crypto-detectors and their ability to locate misuses directly impacts the security of the end user and their data. Evaluating crypto-detectors is an ongoing problem. New misuses are discovered frequently and it is important to have a tool that can keep up with new misuses. The idea behind expanding the MASC framework came from the need to keep up with new misuses and still be a reliable tool for evaluating crypto-detectors. 

The crypto-detectors evaluated in the original paper needed to be reevaluated because bugs that get fixed have a tendency to reappear in future patches.\cite{bkm+18} The newest versions of these tools needed to be reevaluated to see if they have made any improvements with catching misuses and ensure that flaws that were found have truly been fixed. The set of evaluated crypto-detectors was also expanded so that flaws can be reported to other widely used tools to help improve them as well. In addition, since the original paper was published new tools have appeared and gained traction such as Amazon CodeGuru. I wanted to ensure MASC conducted an evaluation on as many crypto-detectors as possible. Since MASC's viability was proven in the original work it was important to extend and improve the work as well as extend its reach. The MASC framework, like many software engineering projects, is an ever evolving framework that is designed to be a reliable way to help evaluate the effectiveness of crypto-detectors.

The motivating example for this new component of the research would be a scenario like the following. Consider Alice, a Java Developer who uses SonarQube as a part of her development pipeline, a known state of the art crypto-detector known for being able to detect security vulnerabilities found in software prior to release. Alice had reported that there was flaw in the crypto-detector that allowed the following line of code to pass without detection:

\inline{Cipher cipher = Cipher . getInstance ( " des " ) ;}

She was told that in the new version of the tool that this would be fixed. Her team upgrades to the latest version and sees that it now detects this misuse. Then some time goes by and another new version is released. Alice's team upgrades to this but one of her team members, Bob, puts the same line of code in the software unaware that it is a misuse. It is able to get through to production since the crypto-detector did not detect it even though Alice reported it previously and is under the belief that it is no longer present.

In addition I continued using the motivation from the original paper of Alice being an unaware developer using:

\inline{Cipher cipher = Cipher . getInstance ( " des " ) ;}

and it not being detected by the crypto-detector. DES is the common version of the misuse, however, Java supports both the uppercase and lowercase versions of this misuse. A crypto-detector would be expected to detect this common mistake.

%--------------------------------------
\subsection{Threat Model}
\label{ch1:subsec:ThreatModel}
%--------------------------------------

The threat model remains the same between both this extension of work as well as the original. In the original paper they defiend the scope of their evaluation by leveraging the documentation of popular crypto-detectors to uderstand how to position their tool and what they claim to be capable of. When evaluating the new tools I looked through their documentation as well and ensured that they made similar claims as the originally evaluated crypto-detectors to ensure the model was consitent across all evaluated crypto-detectors. As an example snyk's documentation claims "Empower developers to become quasi-security professionals with Snyk Code’s comprehensive security tooling." \cite{snyk} Once again similarly Amazon Code Guru claims "Our security detectors use machine learning and automated reasoning to analyze data flow to perform whole-program inter-procedural analysis, across classes, methods, and files to detect hard-to-find security vulnerabilities." \cite{codeguru} and "Java Crypto Library Best Practices help you check common Java cryptography libraries, such as Javax.Crypto.Cipher, to identify that they are initialized and called correctly" or SonarQube says "maximum protection with taint analysis." \cite{sonarqube} All five of the newly evaluated crypto-detectors make similar claims of security assurance. Just like the original nine crypto-detectors that were evaluated and now reevaluated they need to be evaluted by a 3rd party to verify their claims and assure developers that they can truly do what claim they can.

For my threat model I continued off the same model used in the original paper. It assumed that there are some circumstances where they might be deployed in adversarial circumstances due to their claims of being useful for security audits and similar tasks. There are some circumstances where security audits are required and one of the parties involved is opposed to this such as verification for deploying an app in the Google Play Store. To reiterate the threat model consists of three types of adversaries (T1-T3). This threat model is how components of MASC are designed and guide how evaluation was conducted:

T1 Benign developer, accidental misuse - this model assumes the developer accidentally misuses crypto-API, but attempts to detect and address the vulnerabilities with the assistance of crypto-detector.

T2 Benign developer, harmful fix - This scenario shares some similarities to the first as it assumes the developer does not fully understand crypto-API but they are using a tool to help identify misuses. When a misuse gets flagged the developer attempts to fix it but introduces a new vulnerability in its place.

T3 Evasive developer, harmful fix - This assumes the developer is trying to finish the task quickly or with low effort and is intentionally trying to evade the crypto-detector. When the alert from a detector is received the developer will do quick fix that results in potentially hiding the misuse rather than truly fixing it.

Once again like the original design of MASC the threats are meant to mimic how crypto-detectors have to operate in practice and the evaluation is designed based on what the crypto-detectors should be detecting. However, there is a gap between what should be and what is. This is why just like the design of the original MASC I kept all use cases in consideration. 

However, I did try to further capture the T3 developer compared to the original work. In the original work the T3 developer was intially designed to be somewhat conservative to ensure that cases were as close to reality as possible. The original developer were aware that they could go further but they wanted to be more conservative than some real life examples they had seen. For this extension it was discovered that there are cases far more complex and malicious than was originally realized. So in the expansion of MASC some operators were added to include more complex T3 cases.

%--------------------------------------
\section{Related Works}
\label{ch1:sec:relatedworks}
%--------------------------------------

Security researchers have recently shown significant interest in the external validation of static analysis tools
 ~\cite{QWR18,droidbench,iccbench,PBW18,bkm+18,}. %
Particularly, there is a growing realization that static analysis security tools are sound in theory, but {\em soundy in practice}, \ie consisting of a core set of sound decisions, as well as certain strategic unsound choices made for practical reasons such as performance or precision~\cite{lss+15}.

Sound{\em y} tools are desirable for security analysis as their sound core ensures sufficient detection of targeted behavior, while also being {\em practical}, \ie without incurring too many false alarms.

However, given the lack of oversight and evaluation they have faced so far, {\em \detectors} may violate this basic assumption behind sound{\em i}ness and may in fact be {\em unsound}, \ie have fundamental flaws that prevent them from detecting even straightforward instances of crypto-API misuse observed in apps.
This intuition drives our approach for systematically evaluating \detectors, leading to novel contributions that deviate from related work.

To the best of our knowledge, \tool is the first framework to use mutation testing, combined with a large-scale data-driven taxonomy of crypto-API misuse, for comprehensively evaluating the detection ability of \detectors to find design/implementation flaws.
However, in a more general sense, Bonett et al.~\cite{bkm+18} were the first to leverage the intuition behind mutation testing for evaluating Java/Android security tools, and developed the $\mu$SE framework for evaluating data leaks detectors (\eg FlowDroid~\cite{arf+14} and Argus~\cite{wror14}).
\tool significantly deviates from $\mu$SE in terms of its design focus, in order to address the unique challenges imposed by the problem domain of crypto-misuse detection. Particularly, \muse assumes that for finding flaws, it is sufficient to {\em manually} define "a" security operator and strategically place it at hard-to-reach locations in source code.
This assumption does not hold when evaluating \detectors as it is improbable to cast cryptographic misuse as a single mutation, given that cryptographic misuse cases are diverse, and developers may express the same type of misuse in different ways.
For example, consider three well-known types of misuse that would require unique mutation operators: {\sf (1)} using \DES for encryption (operator inserts prohibited parameter names, \eg\ \DES), {\sf (2)} trusting all SSL/TLS certificates (operator creates a malformed \trustManager), and {\sf (3)} using a predictable initialization vector (IV) (operator derives predictable values for the IV).
In fact, developers may even express the same misuse in different ways, necessitating unique operators to express such distinct {\em instances}, \eg the \DES misuse expressed differently in Listing~\ref{lst:des-example} and Listing~\ref{lst:des-misuse-2}.
Thus, instead of adopting \muse's single-operator approach, \tool designs general usage-based mutation operators that can expressively instantiate misuses from our taxonomy of misuses.
In a similar manner, \tools contextualized mutation abstractions (\ie for evaluating \detectors) distinguish it from other systems that perform vulnerability injection for C programs~\cite{dhk+16}, discover API misuse using mutation~\cite{WLW+19,GKL+19}, or evaluate static analysis tools for precision using handcrafted benchmarks or user-defined policies~\cite{QWR18,PBW18}.


Finally, the goal behind \tool is to assist the designers of \detectors~\cite{fhm+12,ebfk13,cognicrypteclipse,knr+17,KSA+18,deepsource,snyk,sonarqube,codeguru,codiga} in identifying design and implementation gaps in their tools, and hence, \tool is complementary to the large body of work in this area.
Particularly, prior work provides rule-sets or benchmarks~\cite{BDA+17,BDA+19} consisting of a limited set of cryptographic ``bad practices''~\cite{BD16}, or taxonomies of smaller subsets (\eg SSL/TLS misuse taxonomy by Vasan et al.~\cite{NVK16}).
However, we believe that the new extended taxonomy is the most systematically-driven and comprehensive taxonomy of {\em crypto-API} misuse, that is further expanded upon into numerous unique misuse instances through \tools operators.
Thus, relative to prior handcrafted benchmarks, \tool can thoroughly test detectors with a far more comprehensive set of crypto-misuse instances.

In addition to the previous work while working on the extension I also looked at other tools trying to accomplish similar goals to MASC such as \cite{Afrose_Xiao_Rahaman_Miller_Yao_2022} and \cite{Schlichtig_Wickert_Krüger_Bodden_Mezini_2022}. I compared what we have done to what these tools are trying to do to ensure that MASC is still state of the art and is keeping up to date with other tools. MASC is still capable of doing more with mutation testing and its operators than these other tools. I still believe MASC is the state of the art tool for identifying flaws in Crypto-Detectors especially after the extension of work.






%--------------------------------------
\section{Bibliographical Notes}
\label{ch1:sec:bibliographicalNotes}
%--------------------------------------

The paper supporting the content described in this Chapter was written in by other members of the SEMERU group at William \& Mary:

Ami, A., Cooper, N., Kafle, K., Moran, K., Poshyvanyk, D., and Nadkarni, A., "Why Crypto-detectors Fail: A Systematic Evaluation of Cryptographic Misuse Detection Techniques", in Proceedings of IEEE Symposium on Security and Privacy (SP'22) May 22, 2022, pp. 614-631

This paper is the basis for the extension described throughout this work. MASC is also moticated partially by another project called µSE done by the SEMERU group at William \& Mary:

Ami, A., Kafle, K., Moran, K., Nadkarni, A., and Poshyvanyk, D., “Systematic Mutation-based Evaluation of the Soundness of Security-focused Android Static Analysis Techniques”, ACM Transactions on Security \& Privacy (TOPS), vol. 24, no. 3, February 2021, pp. 1-37

Bonett, R., Kafle, K., Moran, K., Nadkarni, A., and Poshyvanyk, D., “Discovering Flaws in Security-Focused Static Analysis Tools for Android using Systematic Mutation”, in Proceedings of 27th USENIX Security Symposium (USENIX’18), Baltimore, MD, USA, August 15-17, 2018, pp. 1263-1280

Ami, A., Kafle, K., Moran, K., Nadkarni, A., and Poshyvanyk, D., “µSE: Mutation-based Evaluation of Security-focused Static Analysis Tools for Android”, in Proceedings of the 43rd IEEE/ACM International Conference on Software Engineering (ICSE’21), Formal Tool Demonstration, Virtual (originally Madrid, Spain), May 25th - 28th, 2021, pp. 53-56